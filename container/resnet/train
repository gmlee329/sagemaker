#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import sys
import traceback

import tensorflow as tf
import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras import layers
from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D
from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger
from keras.models import load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import applications
from keras.utils.np_utils import to_categorical
import numpy as np

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # # Read in any hyperparameters that the user passed with the training job
        # with open(param_path, 'r') as tc:
        #     trainingParams = json.load(tc)

        # # Take the set of files and read them all into a single pandas dataframe
        # input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        # if len(input_files) == 0:
        #     raise ValueError(('There are no files in {}.\n' +
        #                       'This usually indicates that the channel ({}) was incorrectly specified,\n' +
        #                       'the data specification in S3 was incorrectly specified or the role specified\n' +
        #                       'does not have permission to access the data.').format(training_path, channel_name))
        # raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
        # train_data = pd.concat(raw_data)

        # # labels are in the first column
        # train_y = train_data.iloc[:,0]
        # train_X = train_data.iloc[:,1:]

        # # Here we only support a single hyperparameter. Note that hyperparameters are always passed in as
        # # strings, so we need to do any necessary conversions.
        # max_leaf_nodes = trainingParams.get('max_leaf_nodes', None)
        # if max_leaf_nodes is not None:
        #     max_leaf_nodes = int(max_leaf_nodes)

        # # Now use scikit-learn's decision tree classifier to train the model.
        # clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)
        # clf = clf.fit(train_X, train_y)

        # # save the model
        # with open(os.path.join(model_path, 'decision-tree-model.pkl'), 'wb') as out:
        #     pickle.dump(clf, out)
        
        ####################################################################################################################
        input_files = { npy_file : os.path.join(training_path, npy_file) for npy_file in os.listdir(training_path) }
        X_train = np.load(input_files['x_train.npy'])
        X_val = np.load(input_files['x_validation.npy'])
        X_test = np.load(input_files['x_test.npy'])

        # X_train = X_train[:10]
        # X_val = X_val[:10]

        y_train = np.load(input_files['y_train.npy'])
        y_val = np.load(input_files['y_validation.npy'])
        y_test = np.load(input_files['y_test.npy'])
        y_train = to_categorical(y_train)
        y_val = to_categorical(y_val)
        y_test = to_categorical(y_test)

        # y_train = y_train[:10]
        # y_val = y_val[:10]

        # 전이학습 시킬 모델 만드는 함수
        def new_model(pre_model, num_category, learning_rate):
            base_input = pre_model.layers[0].input      # pre_model의 input layer의 input을 가져온다.
        
            # pre_model의 최종 later의 ouotput(분류기 전 단계)을 받아와서 GAP를 한후 활성화 layer을 마지막에 추가해준다.
            base_output = pre_model.layers[-1].output  
            x = GlobalAveragePooling2D(name = 'GAPL')(base_output) 
            x = Dropout(0.5)(x)
            final_output = Dense(num_category, activation = 'softmax')(x)

            new_model = Model(inputs = base_input, outputs=final_output)
            optimizer = Adam(learning_rate=learning_rate)

            new_model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])
            return new_model


        ICResNet = applications.InceptionResNetV2(include_top=False, input_shape=(80,80,3))
        # DenseNet = applications.DenseNet201(include_top=False,input_shape=(100,100,3))

        ICResNet_model = new_model(ICResNet, 9, 0.001)
        # DenseNet_model = new_model(DenseNet, 9, 0.001)

        mc = ModelCheckpoint(os.path.join(model_path, 'model{epoch:02d}-{val_accuracy:.2f}.h5'), monitor='val_accuracy', mode='max', save_best_only=True)
        es = EarlyStopping(monitor='val_accuracy', patience=7, mode='max', restore_best_weights=True)

        ICRN_hist = ICResNet_model.fit(X_train, y_train, batch_size=256, epochs=15, validation_data=(X_val, y_val), callbacks=[es,mc])
        print('Training complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
